{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6848168c-aca6-43d7-a951-2d2d2d4226c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets ijson huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e29d2a7-53bc-4453-a4c5-72b05f1b2dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded: PangeaIns.json\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "import json\n",
    "\n",
    "# Initialize the API client\n",
    "api = HfApi()\n",
    "dataset_name = \"neulab/PangeaInstruct\"\n",
    "\n",
    "# Retrieve and download all files in the dataset\n",
    "files = api.list_repo_files(repo_id=dataset_name, repo_type=\"dataset\")\n",
    "\n",
    "for file in files:\n",
    "    if file.startswith(\"PangeaIns.json\"):\n",
    "        hf_hub_download(repo_id=dataset_name, filename=file, repo_type=\"dataset\", cache_dir = \"downloads\")\n",
    "        print(f\"File downloaded: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cf9bcb9-0d7a-49cc-8028-88ac1ab635a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_sample(sample, tasks, target_languages=['en']):\n",
    "    \"\"\"\n",
    "    Check if any task in `tasks` is a substring of `sample['id']`\n",
    "    and if `sample['language']` is in the list of target languages.\n",
    "\n",
    "    Parameters:\n",
    "    - sample (dict): The sample to validate.\n",
    "    - tasks (list of str): List of task substrings to look for in the ID.\n",
    "    - target_languages (list of str): Accepted language values.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if conditions are met, False otherwise.\n",
    "    \"\"\"\n",
    "    # Validate structure\n",
    "    if not isinstance(sample, dict): #or 'id' not in sample or 'language' not in sample:\n",
    "        return False\n",
    "\n",
    "    sample_id = str(sample.get('image', ''))\n",
    "    sample_lang = str(sample.get('language', ''))\n",
    "\n",
    "    if not isinstance(sample_id, str) or not isinstance(sample_lang, str):\n",
    "        return False\n",
    "\n",
    "    # Normalize inputs\n",
    "    sample_id = sample_id.lower()\n",
    "    sample_lang = sample_lang.lower()\n",
    "    tasks = [lang.lower() for lang in tasks]\n",
    "    target_languages = [lang.lower() for lang in target_languages]\n",
    "\n",
    "    # Check if any task is a substring of the sample ID\n",
    "    id_contains_task = any(task.lower() in sample_id for task in tasks)\n",
    "\n",
    "    # Check if language is in target languages\n",
    "    is_target_language = sample_lang in target_languages\n",
    "\n",
    "    return id_contains_task and is_target_language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ddcf25-eff5-46d4-bc95-bf37bac12edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering: 5433377it [01:30, 59865.64it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     objects \u001b[38;5;241m=\u001b[39m ijson\u001b[38;5;241m.\u001b[39mitems(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m tqdm(objects, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltering\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# calculate_language_distributions(obj, )\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_valid_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_languages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     19\u001b[0m             filtered_items\u001b[38;5;241m.\u001b[39mappend(obj)\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# print(obj)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Now `filtered_items` contains only the valid objects\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m, in \u001b[0;36mis_valid_sample\u001b[0;34m(sample, tasks, target_languages)\u001b[0m\n\u001b[1;32m     26\u001b[0m sample_lang \u001b[38;5;241m=\u001b[39m sample_lang\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     27\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [lang\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m tasks]\n\u001b[0;32m---> 28\u001b[0m target_languages \u001b[38;5;241m=\u001b[39m [lang\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m target_languages]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Check if any task is a substring of the sample ID\u001b[39;00m\n\u001b[1;32m     31\u001b[0m id_contains_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(task\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m sample_id \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks)\n",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m sample_lang \u001b[38;5;241m=\u001b[39m sample_lang\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     27\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [lang\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m tasks]\n\u001b[0;32m---> 28\u001b[0m target_languages \u001b[38;5;241m=\u001b[39m [\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m target_languages]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Check if any task is a substring of the sample ID\u001b[39;00m\n\u001b[1;32m     31\u001b[0m id_contains_task \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(task\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m sample_id \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ijson\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "json_path = \"downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/PangeaIns.json\"\n",
    "\n",
    "# Task and language settings\n",
    "# tasks = ['ChartQA', 'doc-vqa', 'table-vqa', 'allava_laion', 'cambrian', 'laion_gpt4v', 'GQA']\n",
    "tasks = ['cambrian', 'ALLaVA-4V','allava_vflan', 'MTVQA',  'nvlr2-llava', \"translation\", 'ChartQA', 'Viet-ShareGPT-4o-Text-VQA', 'Viet-OCR-VQA', 'Viet-Doc-VQA', 'table-vqa', 'doc-vqa',\n",
    "        \"laion-caption\",\"NuminaMath-CoT\", \"OpenHermes-2.5\", 'text_only' , 'ocr', 'cultural/laion-cultural-150k']\n",
    "target_language = ['arabic','bengali','bn','hindi', 'ja', 'hi', 'russian', 'ru', 'spanish', 'es','vietnamese', 'vi', 'zh_simplified','ar','en','english', 'fr', 'Japanese', 'French']\n",
    "\n",
    "# Load and filter items\n",
    "filtered_items = []\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    objects = ijson.items(f, \"item\")\n",
    "    for obj in tqdm(objects, desc=\"Filtering\"):\n",
    "        # calculate_language_distributions(obj, )\n",
    "        if is_valid_sample(obj, tasks, target_languages = target_language):\n",
    "            filtered_items.append(obj)\n",
    "        # print(obj)\n",
    "        # break\n",
    "\n",
    "# Now `filtered_items` contains only the valid objects\n",
    "print(f\"Total valid items: {len(filtered_items)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1661339-cd84-410d-ac1a-1ea68cce4f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1588164 filtered items to filtered_PangeaIns.json\n"
     ]
    }
   ],
   "source": [
    "output_path = \"filtered_PangeaIns.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_items, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(filtered_items)} filtered items to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e6ab4c-ad35-4cc7-8de6-9f0dcf7cb0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"general/cambrian/\",\n",
    "    \"general/ALLAVA-4V/\",\n",
    "    \"general/allava_vflan/\",\n",
    "    \"general/MTVQA/\",\n",
    "    \"general/nvlr2-llava/\",\n",
    "    \"translation/\",\n",
    "    \"doc+chart/ChartQA/\",\n",
    "    \"general/Viet-ShareGPT-4o-Text-VQA/\",\n",
    "    \"doc+chart/Viet-OCR-VQA/\",\n",
    "    \"doc+chart/Viet-Doc-VQA/\",\n",
    "    \"doc+chart/table-vqa/\",\n",
    "    \"doc+chart/doc-vqa/\",\n",
    "    \"text-only/NuminaMath-CoT/\",\n",
    "    \"text-only/Openhermes-2.5/\",\n",
    "    \"text-only/\",  # generic path for text_only task\n",
    "    \"ocr/webui_multilingual_ocr/\",\n",
    "    \"cultural/laion-cultural-150k/\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c096738-397a-49f8-b9d7-20c3d4dcd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "import os\n",
    "\n",
    "# Initialize the API client\n",
    "api = HfApi()\n",
    "dataset_name = \"neulab/PangeaInstruct\"\n",
    "\n",
    "# Retrieve all files in the dataset\n",
    "files = api.list_repo_files(repo_id=dataset_name, repo_type=\"dataset\")\n",
    "\n",
    "# List of target subdirectories\n",
    "target_paths = [\n",
    "    \"general/cambrian/\",\n",
    "    \"general/ALLaVA-4V/\",\n",
    "    \"general/allava_vflan/\",\n",
    "    \"general/MTVQA/\",\n",
    "    \"general/nvlr2-llava/\",\n",
    "    \"translation/\",\n",
    "    \"doc+chart/ChartQA/\",\n",
    "    \"general/Viet-ShareGPT-4o-Text-VQA/\",\n",
    "    \"doc+chart/Viet-OCR-VQA/\",\n",
    "    \"doc+chart/Viet-Doc-VQA/\",\n",
    "    \"doc+chart/Viet-DOC-VQA-II/\",\n",
    "    \"doc+chart/table-vqa/\",\n",
    "    \"doc+chart/doc-vqa/\",\n",
    "    \"text-only/NuminaMath-CoT/\",\n",
    "    \"text-only/Openhermes-2.5/\",\n",
    "    \"ocr/webui_multilingual_ocr/\",\n",
    "    \"cultural/laion-cultural-150k/\"\n",
    "]\n",
    "\n",
    "# Download non-JSON files only from specified paths\n",
    "for file in files:\n",
    "    if any(file.startswith(path) for path in target_paths) and not file.endswith(\".json\"):\n",
    "        local_file = hf_hub_download(\n",
    "            repo_id=dataset_name,\n",
    "            filename=file,\n",
    "            repo_type=\"dataset\",\n",
    "            cache_dir=\"downloads\"\n",
    "        )\n",
    "        print(f\"Downloaded: {file} -> {local_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228d0d59-33ab-4c45-8fdd-7ffaa8c3445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa79fbd-2b4d-4301-9f30-eeeb7c664c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scanning for tarballs and split archives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories: 0it [00:00, ?it/s]\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "                                                      \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 14it [00:00, 61.20it/s]             \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories: 21it [00:00, 37.31it/s]\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories: 25it [00:00, 33.61it/s]\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 29it [00:00, 24.53it/s]             \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 32it [00:01, 23.59it/s]             \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 35it [00:01, 22.88it/s]             \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 38it [00:01, 22.26it/s]             \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 41it [00:01, 21.97it/s]             \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/textvqa.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories: 41it [00:19, 21.97it/s]\n",
      "Checking files:  12%|█▎        | 1/8 [01:51<12:59, 111.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/ocr_vqa.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:  25%|██▌       | 2/8 [06:23<20:37, 206.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/gqa.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:  38%|███▊      | 3/8 [12:02<22:14, 266.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/dvqa.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:  50%|█████     | 4/8 [24:26<30:20, 455.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/docvqa.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:  62%|██████▎   | 5/8 [25:59<16:13, 324.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/coco.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:  75%|███████▌  | 6/8 [35:25<13:33, 406.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/chartqa.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:  88%|████████▊ | 7/8 [36:43<04:59, 299.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n",
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images/ai2d.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files: 100%|██████████| 8/8 [37:13<00:00, 213.45s/it]\u001b[A\n",
      "Walking directories: 44it [37:14, 205.95s/it]                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/cambrian/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/80000 [00:00<?, ?it/s]\u001b[A\n",
      "Checking files:  90%|████████▉ | 71751/80000 [00:00<00:00, 717493.58it/s]\u001b[A\n",
      "Walking directories: 46it [37:15, 163.03s/it]                            \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/21953 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/33074 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 51it [37:15, 93.46s/it]             \u001b[A\n",
      "Checking files:   0%|          | 0/53343 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/Viet-ShareGPT-4o-Text-VQA/images.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories: 51it [37:30, 93.46s/it]\n",
      "Checking files: 100%|██████████| 1/1 [03:19<00:00, 199.69s/it]\u001b[A\n",
      "Walking directories: 54it [40:35, 86.27s/it]                  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/Viet-ShareGPT-4o-Text-VQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/Viet-OCR-VQA/images.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files: 100%|██████████| 1/1 [09:52<00:00, 592.68s/it]\u001b[A\n",
      "Walking directories: 59it [50:27, 98.84s/it]                  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/Viet-OCR-VQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                     \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/ChartQA/images.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files: 100%|██████████| 1/1 [01:38<00:00, 98.76s/it]\u001b[A\n",
      "Walking directories: 61it [52:06, 89.84s/it]                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/ChartQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                  \u001b[A\n",
      "Checking files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/cultural/laion-cultural-150k/images.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files: 100%|██████████| 1/1 [16:55<00:00, 1015.42s/it]\u001b[A\n",
      "Walking directories: 63it [1:09:02, 176.07s/it]                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/cultural/laion-cultural-150k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking files:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories: 64it [1:09:02, 64.72s/it]        \u001b[A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import re\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = \"downloads\"\n",
    "\n",
    "# Regex patterns for identifying split tar files\n",
    "split_patterns = [\n",
    "    re.compile(r\"(.+\\.tar)\\.part\\d+$\"),         # e.g., file.tar.part01\n",
    "    re.compile(r\"(.+\\.tar\\.gz)\\.\\d+$\"),         # e.g., file.tar.gz.001\n",
    "    re.compile(r\"(.+\\.tar)\\.part[a-z]{2}$\"),    # e.g., file.tar.partaa\n",
    "]\n",
    "\n",
    "def find_and_reconstruct_splits():\n",
    "    seen = set()\n",
    "\n",
    "    print(\"🔍 Scanning for tarballs and split archives...\")\n",
    "    for dirpath, _, filenames in tqdm(os.walk(root_dir), desc=\"Walking directories\"):\n",
    "        for filename in tqdm(filenames, leave=False, desc=\"Checking files\"):\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "\n",
    "            for pattern in split_patterns:\n",
    "                match = pattern.match(filename)\n",
    "                if match:\n",
    "                    base_name = match.group(1)\n",
    "                    if (dirpath, base_name) in seen:\n",
    "                        continue\n",
    "\n",
    "                    seen.add((dirpath, base_name))\n",
    "                    base_path = os.path.join(dirpath, base_name)\n",
    "\n",
    "                    # Collect all matching parts\n",
    "                    parts = sorted([\n",
    "                        f for f in os.listdir(dirpath)\n",
    "                        if f.startswith(os.path.basename(base_name)) and \"combined\" not in f\n",
    "                    ])\n",
    "                    parts = [os.path.join(dirpath, f) for f in parts]\n",
    "\n",
    "                    print(f\"\\n📦 Reconstructing: {base_name} from {len(parts)} parts\")\n",
    "                    combined_path = base_path + \".combined\"\n",
    "\n",
    "                    with open(combined_path, \"wb\") as outfile:\n",
    "                        for part in tqdm(parts, desc=\"Merging parts\", leave=False):\n",
    "                            with open(part, \"rb\") as infile:\n",
    "                                outfile.write(infile.read())\n",
    "\n",
    "                    extract_tar(combined_path, dirpath)\n",
    "                    os.remove(combined_path)\n",
    "                    for part in parts:\n",
    "                        os.remove(part)\n",
    "                    break\n",
    "\n",
    "            # Handle normal tarballs\n",
    "            if filename.endswith((\".tar\", \".tar.gz\", \".tgz\")):\n",
    "                extracted = extract_tar(full_path, dirpath)\n",
    "                if extracted:\n",
    "                    os.remove(full_path)\n",
    "\n",
    "def extract_tar(tar_path, extract_to):\n",
    "    try:\n",
    "        print(f\"📂 Extracting: {tar_path}\")\n",
    "        with tarfile.open(tar_path, \"r:*\") as tar:\n",
    "            members = tar.getmembers()\n",
    "            for member in members:\n",
    "                tar.extract(member, path=extract_to)\n",
    "        print(f\"✅ Done: {extract_to}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to extract {tar_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run it\n",
    "find_and_reconstruct_splits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c63e48-5f4c-4a4b-92d6-999a7aed2897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbae4c48-89c2-46c1-8ece-344788c4c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scanning for zip files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories for ZIPs: 0it [00:00, ?it/s]\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "                                                          \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 14it [00:00, 69.50it/s]        \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 21it [00:00, 39.96it/s]\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 26it [00:00, 32.48it/s]        \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 30it [00:00, 30.86it/s]\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/50000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 34it [00:01, 29.59it/s]\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/4060 [00:00<?, ?it/s]\u001b[A\n",
      "                                                            \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 48it [00:01, 53.49it/s]\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/18317 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 56it [00:01, 59.57it/s]\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/4515 [00:00<?, ?it/s]\u001b[A\n",
      "                                                            \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/115404 [00:00<?, ?it/s]\u001b[A\n",
      "                                                              \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "                                                         \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/10194 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 63it [00:01, 44.70it/s]        \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/200000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                              \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/72140 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 69it [00:01, 27.83it/s]\n",
      "Checking ZIP files:   0%|          | 0/80000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/21953 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 74it [00:02, 27.22it/s]\n",
      "Checking ZIP files:   0%|          | 0/33074 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/53343 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Extracting ZIP: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/allava_vflan/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories for ZIPs: 74it [00:16, 27.22it/s]\n",
      "Checking ZIP files: 100%|██████████| 1/1 [14:54<00:00, 894.66s/it]\u001b[A\n",
      "Walking directories for ZIPs: 77it [14:56, 50.07s/it]             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/allava_vflan/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files:   0%|          | 0/181393 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 78it [14:57, 46.41s/it]         \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/42778 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Extracting ZIP: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/MTVQA/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories for ZIPs: 78it [15:16, 46.41s/it]\n",
      "Checking ZIP files: 100%|██████████| 1/1 [00:47<00:00, 47.10s/it]\u001b[A\n",
      "Walking directories for ZIPs: 81it [15:44, 39.02s/it]            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/general/MTVQA/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Extracting ZIP: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/table-vqa/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files: 100%|██████████| 1/1 [01:00<00:00, 60.12s/it]\u001b[A\n",
      "Walking directories for ZIPs: 83it [16:44, 37.35s/it]            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/table-vqa/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Extracting ZIP: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/doc-vqa/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files: 100%|██████████| 1/1 [00:49<00:00, 49.13s/it]\u001b[A\n",
      "Walking directories for ZIPs: 84it [17:33, 38.74s/it]            \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/doc-vqa/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/137098 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 86it [17:34, 29.03s/it]         \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Extracting ZIP: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/Viet-Doc-VQA/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Walking directories for ZIPs: 86it [17:46, 29.03s/it]\n",
      "Checking ZIP files: 100%|██████████| 1/1 [03:43<00:00, 223.84s/it]\u001b[A\n",
      "Walking directories for ZIPs: 87it [21:17, 58.69s/it]             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done extracting: downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4/doc+chart/Viet-Doc-VQA/images.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/28299 [00:00<?, ?it/s]\u001b[A\n",
      "                                                             \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files: 0it [00:00, ?it/s]\u001b[A\n",
      "                                      \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/232478 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 92it [21:18, 28.16s/it]         \u001b[A\n",
      "Checking ZIP files:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "Walking directories for ZIPs: 93it [21:18, 13.75s/it]     \u001b[A\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "def extract_zip_files(root_dir=\"downloads\"):\n",
    "    print(\"🔍 Scanning for zip files...\")\n",
    "    for dirpath, _, filenames in tqdm(os.walk(root_dir), desc=\"Walking directories for ZIPs\"):\n",
    "        for filename in tqdm(filenames, leave=False, desc=\"Checking ZIP files\"):\n",
    "            if filename.endswith(\".zip\"):\n",
    "                zip_path = os.path.join(dirpath, filename)\n",
    "                print(f\"\\n📦 Extracting ZIP: {zip_path}\")\n",
    "\n",
    "                try:\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        members = zip_ref.infolist()\n",
    "                        for member in members:\n",
    "                            zip_ref.extract(member, path=dirpath)\n",
    "\n",
    "                    print(f\"✅ Done extracting: {zip_path}\")\n",
    "                    os.remove(zip_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Failed to extract {zip_path}: {e}\")\n",
    "                    \n",
    "extract_zip_files()            # zip extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91220ceb-38f1-469e-afc5-20c4c575abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1588164 filtered items to sample_PangeaIns.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import ijson\n",
    "filtered_items = []\n",
    "with open('filtered_PangeaIns.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    objects = ijson.items(f, \"item\")\n",
    "    for obj in objects:\n",
    "        filtered_items.append(obj)\n",
    "output_path = \"sample_PangeaIns.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_items[-5:-3], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(filtered_items)} filtered items to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2696c079-095f-4c58-967f-060c709f1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "\n",
    "# # Base path where your files are located\n",
    "# base_dir = \"downloads/datasets--neulab--PangeaInstruct/snapshots/d0819917abe1cae38c008de0ca172f885f1f26a4\"\n",
    "\n",
    "# # Paths of the two target images relative to base_dir\n",
    "# files_to_include = [\n",
    "#     \"cambrian/images/coco/train2017/000000132137.jpg\",\n",
    "#     \"cambrian/images/vg/VG_100K/2319635.jpg\"\n",
    "# ]\n",
    "\n",
    "# # Output zip file name\n",
    "# output_zip = \"selected_images.zip\"\n",
    "\n",
    "# # Create the zip\n",
    "# with zipfile.ZipFile(output_zip, \"w\") as zipf:\n",
    "#     for file_rel_path in files_to_include:\n",
    "#         full_path = os.path.join(base_dir, file_rel_path)\n",
    "#         if os.path.exists(full_path):\n",
    "#             zipf.write(full_path, arcname=file_rel_path)\n",
    "#         else:\n",
    "#             print(f\"File not found: {full_path}\")\n",
    "\n",
    "# print(f\"Created zip: {output_zip}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee70c9-7e6d-4994-a213-c506e39445c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
